---
title: "Practical Machine Learning Project"
output: html_document
---

**Synopsis**

In this project we will be building a prediction model to know how a certain user is lifting weights based on data obtained from an accelerometer.

The dataset consists on 5 classes:

. The subject is lifting weights exactly according to the specification (Class A).

. Throwing the elbow to the front (Class B).

. Lifting the dumbbell only halfway (Class C).

. Lowering the dumbbell only halfway (Class D).

. Throwing the hips to the front (Class E).

For more information and description about the dataset, see the official website: <http://groupware.les.inf.puc-rio.br/har>

**Getting the data**

The file "pml-training" will served as our training set.
The file "pml-testing" is a data set without the classes, in other word, we will predict the classes based on our model.

```{r}
if(!file.exists("pml-training.csv"))
{
  download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "pml-training.csv", method = 'curl')
}
dataset <- read.csv("pml-training.csv", na.strings = c("NA", ""))
if(!file.exists("pml-testing.csv"))
{
  download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "pml-testing.csv", method = 'curl')
}
validation <- read.csv("pml-testing.csv")
```

**Data preprocessing**

Import the necessary packages.
```{r}
library(caret)
library(randomForest)
```

Set a seed for reproducibility.

```{r}
set.seed(17)
```

## Create the data partitions. 70% of it will go to the training set and the rest will be the test set.

```{r}
inTrain = createDataPartition(y=dataset$classe, p=0.7, list=FALSE)
training = dataset[inTrain,]
testing = dataset[-inTrain,]
```

Eliminate the NA entries.

```{r}
naColumns = sapply(training, function(x) {sum(is.na(x))}) #Make a vector of all the columns and the number of NA entries
naColumns
columnsWithNA = names(naColumns[naColumns > 0]) #Vector with all the columns that has NA values
training = training[, !names(training) %in% columnsWithNA] #Remove those columns from the training set
names(training)
#Remove unnecessary columns (the first 7 columns)
training <- training[, !names(training) %in% c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window")]
```

## Do the same for the validation set

```{r}
naColumns = sapply(validation, function(x) {sum(is.na(x))}) #Make a vector of all the columns and the number of NA entries
columnsWithNA = names(naColumns[naColumns > 0]) #Vector with all the columns that has NA values
validation = validation[, !names(validation) %in% columnsWithNA] #Remove those columns from the training set.
validation <- validation[, !names(validation) %in% c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window")]
```

## Do the same for the testing set.

```{r}
naColumns = sapply(testing, function(x) {sum(is.na(x))}) #Make a vector of all the columns and the number of NA entries
columnsWithNA = names(naColumns[naColumns > 0]) #Vector with all the columns that has NA values
testing = testing[, !names(testing) %in% columnsWithNA] #Remove those columns from the training set.
testing <- testing[, !names(testing) %in% c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window")]
```

Now, we build the prediction model using Random Forest.

```{r acc}
model <- randomForest(classe ~ .,   data=training, ntree = 50)
predictions <- predict(model, testing)
confusionMatrix(predictions, testing$classe)
modelAcc <- confusionMatrix(predictions, testing$classe)$overall[[1]]
```

Our model is `r modelAcc` accurate.

Now, we will predict the unknown classes of the validation set.

```{r}
predictions <- predict(model, validation)
predictions
```

## Appendix: Figures
1. Correlation Matrix Visualization  
```{r, cache = T}
corrPlot <- cor(trainData[, -length(names(trainData))])
corrplot(corrPlot, method="color")
```
2. Decision Tree Visualization
```{r, cache = T}
treeModel <- rpart(classe ~ ., data=trainData, method="class")
prp(treeModel) # fast plot
```
